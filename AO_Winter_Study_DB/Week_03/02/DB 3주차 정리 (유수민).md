# 3주차 — Connection Pool & 서버 아키텍처

**핵심 질문**

- 서버가 많아지면 DB는 어떻게 버티나?

**내용**

- 요청의 이해
- 서버 스레드 ↔ DB 커넥션 관계
- Pool size 튜닝
- DB가 먼저 죽는 이유

**키워드**

`Request`, `Response`,`Thread`, `Context Switching`, `Concurrency`

## 1. 💡 문제 제기

요청은 가변적이다. 그렇다면 요청이 많을수록 서버 스레드도 늘어나게 된다. 하지만 문득 의문이 생겼다. 서버가 2배, 3배,100배 늘어나면 그 뒤에 붙어있는 단일 DB는 그 부하를 어떻게 견디는 걸까? 단순히 서버만 늘리는 게 답이 아닐 수도 있겠다는 가설을 세우고 공부를 시작했다.

---

## 2. 📝 키워드 정리

- **요청** : ‘변수’, 조절할 수 없는 외부의 파도
- **서버 스레드** : 그 파도를 받아내는 1차 방어선
- **DB 커넥션** : 데이터를 처리하는 최종 게이트
- **서버 스레드** : 내부적인 처리, **서버 증설** : 외부적인 확장
- **스레드 vs 프로세스 :** 프로세스는 실행 중인 프로그램, 스레드는 그 안의 실행 흐름. (자원 공유 여부가 핵심)
- **Concurrency (동시성) vs Parallelism (병렬성) :** 동시성은 '동시에 하는 것처럼 보이게 번갈아 하는 것', 병렬성은 '실제로 물리적으로 동시에 하는 것'.
    - 동시성은 싱글 코어 CPU가 여러 스레드를 아주 빠르게 번갈아 가며 실행(Context Switching)하는 상태. (논리적인 개념)
    - 병렬성은 멀티 코어 CPU에서 각 코어가 여러 작업을 물리적으로 한순간에 동시에 처리하는 상태입니다. (물리적인 개념)
- **Deadlock (교착 상태) :** 모든 스레드가 커넥션을 잡으려고 대기만 하다가 시스템이 멈추는 현상. Pool Size가 너무 작을 때도 발생할 수 있다.

---

## 3. 🔍 핵심 개념 이해 및 연결

### ❶ 요청(Request)과 스레드(Thread)의 상관관계

- **궁금증** : 요청이 많아질수록 서버스레드도 많이 만들면 처리 속도가 빨라지지 않을까?
    - **나의 기존 생각 :** 사용자 요청이 오면 서버는 이를 처리할 일꾼 = 서버 스레드을 보낸다. 일꾼이 많으면 동시에 많은 일을 하니 좋을 것 같았음.
- **공부한 내용**
    - 요청(Request)이 들어오면 스레드는 커넥션을 잡고 DB에 쿼리(Query)를 날려 응답(Response)을 받아옴.
    - 요청(손님)이 늘어나면 서버 스레드(일꾼)도 늘어남.
    - CPU는 한정되어 있는데 일꾼(Thread)만 너무 많아지면 CPU가 실제 일은 안 하고 "누가 다음에 일할지" 결정하는 데 에너지를 더 많이 씀. 이를 **Context Switching**이라 부르며 과도한 스레드 생성은 오히려 독이 됨.
    - 서버가 무게를 못견디고 멈춰버림→ 시스템 전체가 무너짐
    - 스레드가 많아진다고 무조건 좋은 게 아니라 늘어난 스레드만큼 DB가 감당할 수 있도록 커넥션 풀이라는 통제 밸브를 잘 조절하는 것이 핵심.
    - 그래서 엔지니어는 풀 사이즈 튜닝을 통해 그 최적의 접점을 찾는 사람.
    - 서버 설정에서 서버 스레드의 갯수를 제한하는 것을 스레드 풀이라고 함.

### **"요청이 들어오면 서버 내부에서는 어떤 일이 벌어지는가?"**

- **스레드 할당의 메커니즘:** 사용자가 브라우저에서 버튼을 누르면(Request), WAS(Tomcat 등)는 내부의 **Thread Pool**에서 유휴 스레드를 하나 꺼내 해당 요청에 배정함. 이 스레드는 사용자가 원하는 데이터를 가져오기 위해 DB로 향하게 됨.
- **동시성(Concurrency)의 마법과 함정**
    - **서버가 수천 명을 상대하는 비결 :** 우리 서버의 CPU 코어가 4개뿐이라도 수백 명의 요청을 처리할 수 있는 이유는 **동시성(Concurrency)** 덕분. CPU가 여러 스레드를 아주 짧은 시간 간격으로 번갈아 가며 실행하여 마치 동시에 일을 하는 것처럼 보이게 만들기 때문임.
    - **숨겨진 비용 :** 하지만 이 동시성을 구현하기 위해 CPU는 계속해서 작업을 갈아치우는 **Context Switching**을 수행해야 함. 동시성을 높이려고 스레드만 무작정 늘리면 CPU는 실제 연산보다 작업을 교체하는 데 더 많은 자원을 쓰게 되어 시스템 전체 성능이 저하되는 역설이 발생함.
    - 동시성은 양날의 검과 같아서 적절히 조절하지 못하면 Context Switching이라는 비용 때문에 무너지는 것.
- **스레드 수와 성능의 반비례 관계:** 스레드를 많이 만들면 동시에 많은 요청을 처리할 수 있다고 생각하지만 실제로는 CPU 코어 수가 한정되어 있음. 코어는 한 번에 하나의 스레드만 처리할 수 있기 때문에 스레드가 너무 많아지면 **Context Switching(문맥 교환)** 과정에서 이전에 하던 작업의 상태를 저장하고 복구하는 데 CPU 자원을 다 써버리게 됨. 따라서 결과적으로 실제 비즈니스 로직을 처리하는 속도는 느려지는 '스레드 지옥'에 빠지게 됨.

### ❷ DB Connection Pool (DBCP)의 도입 이유

- **비유로 이해하기**
    - 손님(요청)이 올 때마다 매번 주방(DB)으로 가는 새 통로(DB 커넥션)를 뚫는다. (비용과 시간이 엄청나게 소모)
    - **TO-BE:** 미리 10개의 통로를 뚫어놓고(Pool), 손님(요청)이 오면 빈 통로를 하나씩 내준다. 다 쓰면 반납받는다.
    - **결론:** DB 연결 시 발생하는 **Handshake(TCP 연결 등)** 비용을 줄이기 위해 미리 커넥션을 만들어두는 관리 기법이 필수적임.

### **"왜 스레드와 커넥션은 별개로 관리되어야 하는가?"**

- **물리적 연결의 비용:** DB 커넥션을 맺는 과정은 네트워크 레이어에서 3-Way Handshake를 거치고 DB 인증(ID/PW 확인)과 세션 생성이라는 매우 무거운 과정을 거침. 만약 스레드가 일할 때마다 이 과정을 반복하면 정작 데이터를 쿼리하는(요청하는) 시간보다 연결하는 시간이 더 길어짐.
- **연결의 유한성:** 서버 스레드는 메모리가 허용하는 한 수천 개도 만들 수 있지만, DB 커넥션은 DB 서버의 프로세스 설정과 자원에 따라 엄격하게 제한됨. 따라서 **서버 스레드(일꾼)와 DB 커넥션(도구)은 N:M 관계**로 맺어지며, 스레드가 커넥션을 잠시 빌려 쓰고 바로 반납하는 효율적인 관리가 핵심임.

---

## 3. ⚖️ Pool Size 튜닝 : DB가 먼저 죽는 이유

- **궁금증** : 왜 무조건 Pool을 크게 잡으면 안 될까?
    - 가장 흥미로웠고 생각이 많아지는 부분이였음.
1. **서버 측면 :** Pool Size가 크면 대기 없이 일을 처리할 수 있어 좋음.
2. **DB 측면 :** 연결된 모든 커넥션은 DB의 자원(CPU, 메모리)을 점유함.
3. **임계점 :** 서버를 10대로 늘리고 각각 Pool을 100개씩 잡으면 DB는 **1,000개의 연결**을 유지해야 함. 이때 DB 서버의 CPU가 100%를 찍으며 전체 시스템이 멈추게 됨.
    - **💡 깨달음 :** 서버의 확장성(Scalability)은 결국 DB가 감당할 수 있는 커넥션의 한계치 안에서 결정되는 것.
        - 따라서 서버를 늘리는 것이 성능 해결의 만능열쇠가 아니라는 이유를 여기서 알아냄.
        - 서버가 늘어날수록 DB로 향하는 커넥션의 총합이 늘어나기 때문에 DB가 버티지 못하는 전체 시스템이 무너짐.

### **"DB는 왜 서버보다 먼저 지치는가?"**

- **자원 점유의 차이 :** 서버(WAS)는 상태를 저장하지 않는(Stateless) 특성이 강해 메모리가 부족하면 서버를 더 대수(Scale-out)를 늘리면 그만임. 하지만 DB는 모든 데이터의 상태를 관리해야 하며 각 커넥션마다 고유의 메모리 버퍼를 할당해야 함.
- **Pool Size가 너무 클 때의 문제 (DB의 과부하)**
    1. **Disk I/O 병목 :** 수많은 커넥션이 동시에 읽기/쓰기를 시도하면 디스크 헤드가 물리적으로 감당하지 못함.
    2. **Lock 경합 :** 같은 데이터를 수정하려는 커넥션이 많아지면 서로가 끝나기를 기다리는 대기 시간이 기하급수적으로 늘어나게 됨.
- **Pool Size가 너무 작을 때의 문제 (Deadlock)**
    - 예를 들어 하나의 요청을 처리하는 데 2개의 커넥션이 필요한 로직이 있다고 가정해 보자.
    - 전체 커넥션이 10개인데 10명의 사용자가 동시에 들어와 각각 1개씩 커넥션을 점유하면 모두가 나머지 1개를 기다리며 아무도 일을 끝내지 못하는 Deadlock(교착 상태)에 빠질 수 있음.
- **튜닝의 황금비율:** HikariCP 공식 문서에 따르면 `connections = ((core_count * 2) + effective_spindle_count)`라는 공식이 있음.
    - 즉, 무조건 많이 잡는 게 아니라 **CPU 코어 수와 디스크 성능에 맞춰 "DB가 편안하게 처리할 수 있는 수준**"으로 제한하는 것이 오히려 전체 시스템의 처리량을 높이는 길임.
    - 이론적인 공식도 중요하지만 실제 서비스에서는 DB 사양뿐만 아니라 네트워크 대역폭과 애플리케이션의 쿼리 효율에 따라 최적값이 달라짐. 따라서 반드시 부하 테스트(JMeter 등)를 통해 우리 시스템의 임계점을 직접 확인하는 과정이 동반되어야 한다고 함.

---

## 4. 🌐 CS 다각도 관점에서 본 Connection Pool

- 커넥션 풀은 인프라 전체의 효율을 결정하는 핵심 요소임

### ❶ 운영체제(OS) 관점 : 자원 관리와 Context Switching(문맥 교환)

- **Thread Overhead:** OS 입장에서 스레드는 생성과 컨텍스트 스위칭 비용이 발생하는 자원임. 스레드가 많아지면 CPU는 실제 연산보다 스레드 간의 상태를 복구하고 저장하는 데 에너지를 더 쓰게 됨.
- **Process vs Thread:** DB 커넥션은 보통 하나의 세션(Process/Thread)을 점유하므로 OS 레벨에서 파일 디스크립터(File Descriptor) 제한 등에 걸릴 수 있음.

### ❷ 네트워크(Network) 관점: 비용의 최소화

- **TCP 3-Way Handshake:** 새로운 커넥션을 맺을 때마다 발생하는 네트워크 왕복(Round Trip)은 지연 시간(Latency)의 주범임.
- **Keep-Alive:** 커넥션 풀은 HTTP의 Keep-Alive와 유사하게, 한 번 맺은 TCP 연결을 끊지 않고 유지하여 네트워크 부하를 줄이는 전략.

### ❸ 데이터베이스(DB) 관점: 정적 자원의 한계

- **Memory Allocation:** DB는 연결된 각 커넥션마다 고유의 메모리 버퍼(Sort Buffer, Join Buffer 등)를 할당. 커넥션이 무한히 늘어나면 DB 서버는 Out Of Memory(OOM)로 다운됨.
- **Locking & Contention:** 커넥션이 많아지면 같은 데이터 행(Row)에 접근하려는 경합이 심해져 성능이 기하급수적으로 떨어짐.

### ❹ 클라우드(Cloud) 관점: 확장성(Scalability)의 딜레마

- **Auto-Scaling:** 트래픽이 몰려 서버(WAS)가 10대에서 100대로 늘어나면, 각 서버의 Pool이 DB를 공격하게 됩니다. 이를 막기 위해 클라우드 환경에서는 **DB Proxy(예: AWS RDS Proxy)**를 두어 커넥션을 중간에서 집약(Aggregation) 관리하기도 합니다.

---

## 5. 🚨 장애 상황 및 비상 대응 방법

- 실제 서비스에서 문제가 발생했을 때 커넥션 풀이 어떻게 작동하고, 개발자는 어떻게 대응해야 할까?
    - 

### ❶ 서버 다운 및 연결 단절 (Connection Refused)

- **상황 :** DB 서버가 재시작되거나 네트워크 장애로 연결이 끊김.
- **대응 :** 커넥션 풀(예: HikariCP)은 내부적으로 `testOnBorrow`나 **`keepalive`** 쿼리(예: `SELECT 1`)를 날려 연결 유효성을 검사함. 죽은 연결은 즉시 버리고 새 연결을 시도.

### ❷ 커넥션 고갈 (Connection Timeout)

- **상황 :** 모든 커넥션이 사용 중이라 새로운 요청이 대기 상태에 빠짐.
- **현상 :** 사용자 응답 시간이 길어지다가 결국 `ConnectionTimeoutException` 발생.
- **해결 :** 무작정 Pool을 늘리는 게 아니라 Slow Query(느린 쿼리)를 찾아 최적화하거나, 요청 처리 시간을 단축해야 함.

### ❸ DB 서버 과부하 (CPU 100%)

- **상황 :** 서버 대수가 너무 많아 DB가 감당 못 함.
- **전략 (Circuit Breaker) :** 장애가 전파되는 것을 막기 위해 **서킷 브레이커**를 발동시켜 DB 접근을 잠시 차단하고 사용자에게 "점검 중" 메시지를 보여주는 것이 전체 시스템을 살리는 방법.

### ❹ 재연결 폭풍 (Retry Storm)

- **상황:** DB가 복구되자마자 수천 대의 서버가 동시에 재연결을 시도하여 DB가 다시 뻗음.
- **해결:** **Exponential Backoff(지수적 백오프)** 알고리즘을 사용하여 재시도 간격을 점진적으로 늘리며 DB가 숨 쉴 틈을 주어야 함.

---

## 6. 🚩 종합 정리

- 무조건적인 증설보다 중요한 것은 연결의 조화임을 깨달았다.
    - 이번 공부를 통해 그동안 추상적으로만 알고 있던 서버 아키텍처의 실체를 마주할 수 있었다. 특히 서버 스레드(일꾼)와 DB 커넥션(도구)의 조화가 시스템 전체의 생사(生死)를 결정할 만큼 중요하다는 사실이 가장 큰 충격이었다.

### 💡 이번 주차의 핵심 깨달음

- **조화의 중요성 :** 우리가 일상에서 겪는 수많은 서비스 장애와 서버 다운의 이면에는 결국 늘어나는 요청(Request)에 대응하기 위해 무작정 스레드나 풀 사이즈를 늘렸다가 자원의 불균형으로 인해 DB가 먼저 쓰러지는 상황이 있지 않았을까 생각하며 내용이 더 잘 이해되었다.
- **비움의 미학 (Less is More) :** 무조건 일꾼을 많이 투입(Pool Size 확대)하는 것이 정답이 아니라 CPU 코어 수와 디스크 I/O 같은 물리적 한계를 인정하고 그 안에서 **최적의 병목(Bottleneck) 해결 지점**을 찾는 것이 엔지니어의 진짜 실력임을 배웠다.
- **장애를 대하는 자세 :** 장애는 피하는 것이 아니라 방어하고 관리하는 영역임을 알게 되었습니다. 데드락(Deadlock)이나 재연결 폭풍 같은 비상 상황에서 시스템을 어떻게 안전하게 격리하고 복구할지(DBCP 설정 등) 고민하는 과정이 현업에서 얼마나 중요한 가치를 가지는지 깨닫게 되어 뿌듯하다.

### 🚀 향후 실천 계획

단순한 이론을 넘어 **HikariCP의 공식 같은 실제 수식**을 내 서비스에 직접 적용해보고 싶다. 로컬 환경에서 JMeter 같은 도구로 부하 테스트를 진행하며 풀 사이즈를 1씩 조정할 때마다 성능 그래프가 어떻게 요동치는지, 그리고 우리 시스템의 황금 비율은 어디인지 직접 데이터로 증명해보는 과정을 수행해보고 싶다.

### 💡 마무리

- **서버가 많아질 때 DB가 버티는 힘은 무조건적인 확장이 아니라 정교한 조화에서 나온다.**
    - 맛집 대기 줄을 무한정 길게 세우지 않고 식당의 테이블 수와 요리사의 속도에 맞춰 손님을 입장시키는 것처럼 저 또한 앞으로 어떤 서비스를 설계하든 **요청-스레드-커넥션-DB**로 이어지는 이 연결 고리가 가장 아름다운 조화를 이룰 수 있도록 병목을 찾고 해결하는 엔지니어가 되도록 노력해야겠다.